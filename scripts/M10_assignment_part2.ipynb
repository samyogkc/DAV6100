{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "For this portion of the lab, we are going to alter the script, M10_assignment.ipynb, to iterate through the pagination that exists on the page and compile all of the results in one dataframe from each page. Once done , we will save the csv into s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load modules\n",
    "#!pip install webdriver-manager\n",
    "import awscli\n",
    "import boto3\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import StringIO\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "s = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=s)\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element(\n",
    "    By.XPATH, \"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]\")\n",
    "inputElement.send_keys('0')\n",
    "inputElement1 = browser.find_element(\n",
    "    By.XPATH, \"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]\").click()\n",
    "sleep(4)  # allow for the page to load by adding a sleep element\n",
    "#identify the table to scrape\n",
    "table = browser.find_element(By.CSS_SELECTOR, 'table.Bordered')\n",
    "sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "data_list = []\n",
    "\n",
    "# Loop through pages of results\n",
    "\n",
    "while True:\n",
    "    # Loop through dataframe to export table\n",
    "    for row in table.find_elements(By.CSS_SELECTOR, 'tr'):\n",
    "        cols = [cell.text for cell in row.find_elements(By.CSS_SELECTOR, 'td')]\n",
    "        if len(cols) > 0:  # exclude empty rows\n",
    "            data_list.append({\"Organization Name\": cols[0], \"NY Reg #\": cols[1], \"EIN\": cols[2],\n",
    "                              \"Registrant Type\": cols[3], \"City\": cols[4], \"State\": cols[5]})\n",
    "\n",
    "    # Check if there is another page of results\n",
    "    next_button = browser.find_elements(\n",
    "        By.XPATH, \"//a[contains(text(),'Next')]\")\n",
    "    if not next_button:\n",
    "        break\n",
    "    next_button[0].click()\n",
    "    time.sleep(2)  # allow for the page to load by adding a sleep element\n",
    "    table = browser.find_element(By.CSS_SELECTOR, 'table.Bordered')\n",
    "\n",
    "# Concatenate all the dataframes into a single dataframe\n",
    "final_data = pd.concat([pd.DataFrame(list_num, index=[0])\n",
    "               for list_num in data_list], ignore_index=True)\n",
    "\n",
    "# Display the scraped data\n",
    "display(final_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bucket\n",
    "\n",
    "We can create bucket using aws console or using boto3 module in python.\n",
    "In order to create s3 bucket using boto3, we need access key and secret key to access our aws account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the name of the bucket to create\n",
    "bucket_name = 'm10-assignment'\n",
    "\n",
    "aws_access_key = input(\"enter your access key \\n\")\n",
    "aws_secret_key = input(\"enter your secret key \\n\")\n",
    "\n",
    "aws_s3_client = boto3.client('s3', aws_access_key_id=aws_access_key,\n",
    "                             aws_secret_access_key=aws_secret_key)\n",
    "\n",
    "#Below commented code has the access key to my AWS account.\n",
    "response = aws_s3_client.list_buckets()\n",
    "bucket_exist = False\n",
    "\n",
    "for bucket in response['Buckets']:\n",
    "    if bucket['Name'] == bucket_name:\n",
    "        bucket_exist = True\n",
    "        break\n",
    "\n",
    "if bucket_exist:\n",
    "    print(\"The bucket exists\")\n",
    "else:\n",
    "    print(\"The bucket does not exist\")\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "if not bucket_exist:\n",
    "    try:\n",
    "        aws_s3_client.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"{bucket_name} bucket has been created on AWS S3\")\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        print(f\"{bucket_name} cannot be created on S3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading file in s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = 's3://m10-assignment/'\n",
    "filename = 'charities_bureau_scrape_group6_part2'  # name of your group\n",
    "datetime = time.strftime(\"%Y-%m-%d-%H-%M-%S\")  # timestamp\n",
    "# name of the filepath and csv file\n",
    "filenames3 = f\"{filename}-{datetime}.csv\"\n",
    "\n",
    "def upload_s3(final_data, file_name):\n",
    "    csv_buffer = StringIO()\n",
    "    final_data.to_csv(csv_buffer, header=True, line_terminator='\\n')\n",
    "    csv_buffer.seek(0)\n",
    "    aws_s3_client.put_object(\n",
    "        Bucket=bucket_name, Body=csv_buffer.getvalue(), Key=file_name, ACL='public-read')\n",
    "    \n",
    "upload_s3(final_data, filenames3)\n",
    "print(\"Data uploaded successfully \")\n",
    "\n",
    "#print success message\n",
    "print(f\"Successfully uploaded file to location:{pathname}{filenames3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link to file\n",
    "https://m10-assignment.s3.amazonaws.com/charities_bureau_scrape_group6_part2-2023-04-12-20-35-08.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
